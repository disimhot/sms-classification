training:
  learning_rate: 2.1e-5
  per_device_train_batch_size: 32
  per_device_eval_batch_size: 32
  weight_decay: 0.1073
  warmup_ratio: 0.1382
  num_train_epochs: 6
  metric_for_best_model: "f1"
  greater_is_better: true
  seed: 42
  output_dir: "${hydra:run.dir}/outputs"
